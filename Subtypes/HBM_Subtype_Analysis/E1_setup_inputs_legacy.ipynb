{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the model and the inputs for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variable names\n",
    "#regress_vars = ['AGE_AT_SCAN', 'FD_scrubbed']\n",
    "regress_vars = ['SEX', 'AGE_AT_SCAN', 'FD_scrubbed']\n",
    "#model_vars = ['SUB_ID', 'SITE_ID', 'DX_GROUP', 'AGE_AT_SCAN', 'FD_scrubbed']\n",
    "model_vars = ['SEX', 'AGE_AT_SCAN', 'FD_scrubbed']\n",
    "nb_subtypes = 5\n",
    "# 'ADOS_sb_sev', 'SRS_RAW_TOTAL'\n",
    "coi = 'DX_GROUP'\n",
    "scale = 7\n",
    "thing = 'legacy_diag_int_half'\n",
    "\n",
    "model_name = 'model_{}_maybe_sc{}.csv'.format(thing, scale)\n",
    "mat_name = 'model_{}_maybe_sc{}.mat'.format(thing, scale)\n",
    "\n",
    "# Paths\n",
    "proj_dir = '/data1/abide/legacy_test'\n",
    "pheno_in = '/data1/abide/Pheno/site_balanced_279.csv'\n",
    "\n",
    "if not os.path.isdir(proj_dir):\n",
    "    os.makedirs(proj_dir)\n",
    "\n",
    "local_root = '/data1/abide/Out/Scores/sc07/time/rmap_part'\n",
    "#remote_root = '/home/surchs/sim_data/data/abide/'\n",
    "remote_root = local_root\n",
    "\n",
    "# Fixed stuff\n",
    "pipe_folder = os.path.join(proj_dir, 'subtype/sc{}/{}_maybe/'.format(scale, thing))\n",
    "mask_path = '/data1/abide/Mask/mask_data_specific.nii.gz'\n",
    "tpl = '{}_fmri_{:07d}_session_1_run1_rmap_part.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno = pd.read_csv(pheno_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno.SITE_ID.replace({'PITT':'Pitt'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the input structure for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dict = dict()\n",
    "pop_ind = list()\n",
    "path_list = list()\n",
    "sub_list = list()\n",
    "for i, r in pheno.iterrows():\n",
    "    sub_name = 'sub_{}'.format(r.SUB_ID)\n",
    "    rel_path = tpl.format(r.SITE_ID, int(r.SUB_ID))\n",
    "    \n",
    "    loc_path = os.path.join(local_root, rel_path)\n",
    "    rem_path = os.path.join(remote_root, rel_path)\n",
    "    # Check path locally\n",
    "    if not os.path.isfile(loc_path):\n",
    "        print('Something wrong with {}'.format(loc_path))\n",
    "        pop_ind.append(i)\n",
    "    else:\n",
    "        data_dict[sub_name] = rem_path\n",
    "        path_list.append(rem_path)\n",
    "        sub_list.append(sub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_array = np.array(path_list, dtype=object)\n",
    "sub_array = np.array(sub_list, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of those guys\n",
    "pheno.drop(pheno.index[pop_ind], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make dummies for site\n",
    "dummies = pd.get_dummies(pheno['SITE_ID'], prefix='dummie')\n",
    "# Add an intercept\n",
    "#dummies.rename(columns={dummies.columns[0]:'Intercept'}, inplace=True)\n",
    "#dummies.Intercept = np.ones((dummies.shape[0],1))\n",
    "\n",
    "# Drop the first site (because intercept)\n",
    "dummies.drop(dummies.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Get dummie names\n",
    "dummie_names = list(dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not coi in model_vars:\n",
    "    model_vars.append(coi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select and reorder the columns I need to run\n",
    "ordered_pheno = pheno[model_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dummie in dummie_names:\n",
    "    if not dummie in model_vars:\n",
    "        model_vars.append(dummie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add the dummie stuff to it\n",
    "model = pd.merge(ordered_pheno, dummies, left_index=True, right_index=True)\n",
    "# Add the dummies to the regressors\n",
    "regressors = regress_vars + dummie_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save it locally\n",
    "model.to_csv(os.path.join(proj_dir, 'pheno', model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up the files_in\n",
    "file_dict = dict()\n",
    "#file_dict['data'] = data_dict\n",
    "file_dict['mask'] = mask_path\n",
    "file_dict['model'] = os.path.join(proj_dir, 'pheno', model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the opt\n",
    "opt_dict = dict()\n",
    "opt_dict['folder_out'] = pipe_folder\n",
    "opt_dict['scale'] = 7\n",
    "#opt_dict['stack'] = {'regress_conf': np.array(regressors,dtype=object)}\n",
    "opt_dict['subtype'] = {'nb_subtype':nb_subtypes}\n",
    "opt_dict['chi2'] = {'group_col_id':'DX_GROUP'}\n",
    "\n",
    "# Make the regressor thingee\n",
    "cont_dict = dict()\n",
    "for regr in regressors:\n",
    "    cont_dict[regr] = 0\n",
    "# Add the thing I am interested in \n",
    "cont_dict[coi] = 1\n",
    "\n",
    "# Add this\n",
    "opt_dict['association'] = {'contrast':cont_dict, 'fdr':0.05, 'flag_intercept':True, 'normalize_x':False}\n",
    "# Set test to true\n",
    "opt_dict['flag_test'] = True\n",
    "# No figures, octave is too stupid for figures\n",
    "opt_dict['flag_visu'] = True\n",
    "opt_dict['stack'] = {'flag_conf':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up psom options\n",
    "psom_dict = dict()\n",
    "psom_dict['path_logs'] = os.path.join(pipe_folder, 'logs')\n",
    "psom_dict['max_queued'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the whole shebang\n",
    "mat_dict = dict()\n",
    "mat_dict['files_in'] = file_dict\n",
    "mat_dict['opt'] = opt_dict\n",
    "mat_dict['opt_psom'] = psom_dict\n",
    "mat_dict['paths'] = path_array\n",
    "mat_dict['subs'] = sub_array\n",
    "sio.savemat(os.path.join(proj_dir, 'pheno', mat_name), mat_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
